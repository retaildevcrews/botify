{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b",
   "metadata": {},
   "source": [
    "# How to deal with json documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d",
   "metadata": {},
   "source": [
    "Load data from JSON formatted document into the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f6044e-463f-4988-bc46-a3c3d641c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../apps/credentials.env\")\n",
    "\n",
    "def text_to_base64(text):\n",
    "    # Convert text to bytes using UTF-8 encoding\n",
    "    bytes_data = text.encode('utf-8')\n",
    "\n",
    "    # Perform Base64 encoding\n",
    "    base64_encoded = base64.b64encode(bytes_data)\n",
    "\n",
    "    # Convert the result back to a UTF-8 string representation\n",
    "    base64_text = base64_encoded.decode('utf-8')\n",
    "\n",
    "    return base64_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331692ba-b68e-4b99-9bae-5057da9a389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594ff0d4-56e3-4bed-843d-28c7a092069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = AzureOpenAIEmbeddings(deployment=os.environ[\"EMBEDDING_DEPLOYMENT_NAME\"], chunk_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e",
   "metadata": {},
   "source": [
    "## Create Vector-based index\n",
    "\n",
    "\n",
    "Now that we have the content of the book's chunks (each page of each book) in the dictionary `book_pages_map`, let's create the Vector index in our Azure Search Engine where this content is going to land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name= os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
    "print(\"Index name: \", index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b07e84b-d306-4bc9-9124-e64f252dd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Azure Search Vector-based Index\n",
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d63e68-69a5-4b3b-8eb0-86da02cb7230",
   "metadata": {},
   "source": [
    "REST API version 2023-10-01-Preview supports external and internal vectorization. This Notebook assumes an external vectorization strategy. This API also supports:\n",
    "    \n",
    "- vectorSearch algorithms, hnsw and exhaustiveKnn nearest neighbors, with parameters for indexing and scoring.\n",
    "- vectorProfiles for multiple combinations of algorithm configurations.\n",
    "\n",
    "Vector search algorithms include **exhaustive k-nearest neighbors (KNN)** and **Hierarchical Navigable Small World (HNSW)**. Exhaustive KNN performs a brute-force search that scans the entire vector space. HNSW performs an approximate nearest neighbor (ANN) search. While KNN provides exact nearest neighbor search results with high accuracy, its computational cost and poor scalability make it impractical for large datasets or real-time applications. HNSW, on the other hand, offers a highly efficient and scalable solution for nearest neighbor searches by finding approximate nearest neighbors quickly, making it more suitable for large-scale and high-dimensional data applications.\n",
    "\n",
    "\n",
    "check [HERE](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-10-01-Preview%2Crest-2023-11-01%2Cpush%2Cportal-check-index) for the details of the vector configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "index_payload = {\n",
    "    \"name\": index_name,\n",
    "    \"vectorSearch\": {\n",
    "        \"algorithms\": [  # We are showing here 3 types of search algorithms configurations that you can do\n",
    "             {\n",
    "                 \"name\": \"my-hnsw-config-1\",\n",
    "                 \"kind\": \"hnsw\",\n",
    "                 \"hnswParameters\": {\n",
    "                     \"m\": 4,\n",
    "                     \"efConstruction\": 400,\n",
    "                     \"efSearch\": 500,\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "                 \"name\": \"my-hnsw-config-2\",\n",
    "                 \"kind\": \"hnsw\",\n",
    "                 \"hnswParameters\": {\n",
    "                     \"m\": 8,\n",
    "                     \"efConstruction\": 800,\n",
    "                     \"efSearch\": 800,\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "                 \"name\": \"my-eknn-config\",\n",
    "                 \"kind\": \"exhaustiveKnn\",\n",
    "                 \"exhaustiveKnnParameters\": {\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             }\n",
    "        ],\n",
    "        \"vectorizers\": [\n",
    "            {\n",
    "                \"name\": \"openai\",\n",
    "                \"kind\": \"azureOpenAI\",\n",
    "                \"azureOpenAIParameters\":\n",
    "                {\n",
    "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "                    \"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
    "                    \"deploymentId\" : \"text-embedding-ada-002\",\n",
    "                    \"modelName\": \"text-embedding-ada-002\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"profiles\": [  # profiles is the diferent kind of combinations of algos and vectorizers\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-1\",\n",
    "             \"algorithm\": \"my-hnsw-config-1\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            },\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-2\",\n",
    "             \"algorithm\": \"my-hnsw-config-2\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            },\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-3\",\n",
    "             \"algorithm\": \"my-eknn-config\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"semantic\": {\n",
    "        \"configurations\": [\n",
    "            {\n",
    "                \"name\": \"my-semantic-config\",\n",
    "                \"prioritizedFields\": {\n",
    "                    \"titleField\": {\n",
    "                        \"fieldName\": \"title\"\n",
    "                    },\n",
    "                    \"prioritizedContentFields\": [\n",
    "                        {\n",
    "                            \"fieldName\": \"chunk\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"prioritizedKeywordsFields\": []\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
    "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\n",
    "            \"name\": \"chunkVector\",\n",
    "            \"type\": \"Collection(Edm.Single)\",\n",
    "            \"dimensions\": 1536,\n",
    "            \"vectorSearchProfile\": \"my-vector-profile-3\", # we picked profile 3 to show that this index uses eKNN vs HNSW (on prior notebooks)\n",
    "            \"searchable\": \"true\",\n",
    "            \"retrievable\": \"true\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        }\n",
    "\n",
    "    ],\n",
    "}\n",
    "url=f\"{os.environ['AZURE_SEARCH_ENDPOINT']}/indexes/{index_name}\"\n",
    "print(url)\n",
    "r = requests.put(url,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.text)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7dda9-4725-410e-9465-54f0298fc758",
   "metadata": {},
   "source": [
    "## Upload the Document chunks and its vectors to the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0",
   "metadata": {},
   "source": [
    "The following code will iterate over each chunk of each book and use the Azure Search Rest API upload method to insert each document with its corresponding vector (using OpenAI embedding model) to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bcf9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from jsonl file\n",
    "data_file='data.jsonl'\n",
    "data = pd.read_json(data_file, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterarte over dataframe and access each column's value to populate index\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    title=row['title']\n",
    "    keywords=row['keywords']\n",
    "    summary=row['summary']\n",
    "    content=row['content']\n",
    "    source_url=row['source_url']\n",
    "    chunk=f\"\"\"\n",
    "    title: {title}\n",
    "    keywords: {keywords}\n",
    "    summary: {summary}\n",
    "    content: {content}\n",
    "    source url: {source_url}\n",
    "    \"\"\"\n",
    "    # Create the payload\n",
    "    payload = {\n",
    "        \"value\": [\n",
    "            {\n",
    "                \"@search.action\": \"upload\",\n",
    "                \"id\": str(index),\n",
    "                \"title\": title,\n",
    "                \"chunk\": chunk,\n",
    "                \"location\": source_url,\n",
    "                \"chunkVector\": embedder.embed_query(chunk if chunk!=\"\" else \"-------\")\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index_name + \"/docs/index\",\n",
    "                    data=json.dumps(payload), headers=headers, params=params)\n",
    "        print(f\"added article {id} to index\")\n",
    "        if r.status_code != 200:\n",
    "            print(r.status_code)\n",
    "            print(r.text)\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\",e)\n",
    "        print(chunk)\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcel-spike-dY-SZnE2-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
